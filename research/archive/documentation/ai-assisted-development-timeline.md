# AI-Assisted Development Timeline: The REAL Numbers

**Your challenge:** "estimate as AI, if AI builds it, having opencode as code to follow... 1 week with 1 engineer?"

**My brutal answer: You're RIGHT. I was estimating like it's 2019.**

---

## The Old Estimate (Human-Only Development)

**What I said:**
- Build from scratch: 12-16 weeks, 3-4 engineers, $150k-$250k
- Wrap OpenCode: 6-8 weeks, 2-3 engineers, $60k-$100k
- Wrap Claude Code: 4-6 weeks, 2 engineers, $40k-$70k

**Assumptions:**
- Engineers write code manually
- Engineers debug manually
- Engineers write tests manually
- Engineers write docs manually
- Engineers search Stack Overflow for solutions
- Meetings, code reviews, back-and-forth

**This is 2019 thinking. WRONG for 2025.**

---

## The NEW Reality (AI-Assisted Development)

**What you have:**
- Claude Code / Claude API (writes code)
- OpenCode source code (reference implementation)
- Clear architecture (from our analysis)
- Clear requirements (role-based CLI)
- Reference patterns (from other tools)

**What AI can do NOW:**

### Day 1: Architecture + Core Types (8 hours)

**Human does:**
- Define roles structure
- Define permission model
- Write high-level architecture doc

**Claude Code does:**
```typescript
// Human: "Create TypeScript types for role system based on this spec"
// Claude generates in 30 seconds:

export interface Role {
  id: string
  name: string
  systemPrompt: string
  permissions: {
    canRead: ResourcePermissions
    canWrite: ResourcePermissions
  }
  knowledgeCategories: string[]
  mcpAccess: Record<string, "full" | "readonly" | "blocked">
}

export interface ResourcePermissions {
  code: boolean
  tests: boolean
  designs: boolean
  docs: boolean
  tickets: boolean
  database: boolean
}

// + 20 more types in 5 minutes
```

**Human does:** Review, adjust, approve (1 hour)

**AI does:** Generate all boilerplate (6 hours of human work ‚Üí 30 minutes)

---

### Day 2: Permission System (8 hours)

**Human does:**
- Write failing test cases
- Define edge cases

**Claude Code does:**
```typescript
// Human: "Implement PermissionEnforcer class based on these tests"
// Claude generates full implementation in 2 minutes

export class PermissionEnforcer {
  constructor(private role: Role) {}

  canRead(resource: Resource): boolean {
    const type = this.detectResourceType(resource)
    return ROLES[this.role].permissions.canRead[type]
  }

  canWrite(resource: Resource): boolean {
    const type = this.detectResourceType(resource)
    return ROLES[this.role].permissions.canWrite[type]
  }

  enforceRead(resource: Resource): void {
    if (!this.canRead(resource)) {
      throw new PermissionDeniedError(
        `Role '${this.role}' cannot read ${resource.type}`,
        this.getSuggestion(resource)
      )
    }
  }

  // ... 200 more lines in 3 minutes
}
```

**Human does:**
- Run tests (pass ‚úÖ)
- Add edge cases
- Review error messages
- Total: 2 hours

**AI does:** Write 500 lines of code (3 days of human work ‚Üí 2 hours)

---

### Day 3: Knowledge System (8 hours)

**Human does:**
- Define knowledge structure
- Write knowledge-map.ts
- Define tag hierarchy

**Claude Code does:**
```typescript
// Human: "Implement KnowledgeLoader that loads core + role + tag knowledge,
//         analyzes tasks for tags, filters by role permissions"
// Claude generates in 5 minutes:

export class KnowledgeLoader {
  async load(role: Role, task: string): Promise<string> {
    const knowledge = []

    // Core knowledge
    knowledge.push(...await this.loadCore())

    // Role knowledge
    const roleCategories = ROLES[role].knowledgeCategories
    knowledge.push(...await this.loadCategories(roleCategories))

    // Task-specific tags
    const tags = await this.analyzeTags(task)
    const filteredTags = this.filterTagsByRole(tags, role)
    knowledge.push(...await this.loadTags(filteredTags))

    return this.concatenate(knowledge)
  }

  private async analyzeTags(task: string): Promise<string[]> {
    // Uses Anthropic API to extract tags
    const response = await this.anthropic.messages.create({
      model: "claude-3-haiku-20240307",
      max_tokens: 100,
      messages: [{ role: "user", content: this.buildTagPrompt(task) }]
    })
    return JSON.parse(response.content[0].text)
  }

  // ... 300 more lines
}
```

**Human does:**
- Test with real knowledge files
- Verify tag extraction works
- Optimize caching
- Total: 3 hours

**AI does:** Write 400 lines of code (4 days of human work ‚Üí 3 hours)

---

### Day 4: OpenCode Wrapper (8 hours)

**Human does:**
- Study OpenCode API
- Define integration points

**Claude Code does:**
```typescript
// Human: "Create OpenCodeExecutor that wraps OpenCode client,
//         injects role system prompt, enforces permissions"
// Claude generates in 10 minutes (has OpenCode source as reference):

export class OpenCodeExecutor {
  constructor(private opencode: OpenCodeClient) {}

  async execute(params: ExecuteParams): Promise<ExecutionResult> {
    const { role, command, systemPrompt } = params

    // 1. Create session with custom system prompt
    const session = await this.opencode.createSession({
      agent: "general",
      system: systemPrompt,
      permissions: this.convertPermissions(role)
    })

    // 2. Execute command
    const result = await this.opencode.run(session, command)

    // 3. Parse operations
    const operations = this.parseOperations(result)

    // 4. Enforce write permissions
    for (const op of operations) {
      if (op.type === "write" && !this.canWrite(role, op.resource)) {
        await this.revertOperation(op)
        throw new PermissionDeniedError()
      }
    }

    return result
  }

  // ... 250 more lines
}
```

**Human does:**
- Test against real OpenCode
- Handle edge cases
- Debug integration issues
- Total: 4 hours

**AI does:** Write 300 lines (3 days ‚Üí 4 hours)

---

### Day 5: CLI Interface (8 hours)

**Human does:**
- Design CLI UX
- Write command specs

**Claude Code does:**
```typescript
// Human: "Create CLI with role selection, command execution,
//         context expansion, interactive prompts"
// Claude generates in 15 minutes:

export class RoleBasedCLI {
  private role: Role
  private executor: OpenCodeExecutor
  private knowledge: KnowledgeLoader

  async run() {
    // Interactive setup
    this.role = await this.selectRole()

    console.log(`‚úÖ Role: ${ROLES[this.role].name}`)
    console.log(`üìö Knowledge: ${ROLES[this.role].knowledgeCategories.join(", ")}`)
    console.log(`üîß MCPs: ${this.listMCPs(this.role)}`)

    // Command loop
    while (true) {
      const input = await prompt("$ ")

      if (input === "/exit") break
      if (input === "/expand-context") {
        await this.handleContextExpansion()
        continue
      }

      await this.executeCommand(input)
    }
  }

  private async executeCommand(command: string) {
    try {
      // Load knowledge
      const knowledge = await this.knowledge.load(this.role, command)

      // Build system prompt
      const systemPrompt = this.buildSystemPrompt(this.role, knowledge)

      // Execute
      const result = await this.executor.execute({
        role: this.role,
        command,
        systemPrompt
      })

      console.log(result.output)

    } catch (error) {
      this.handleError(error)
    }
  }

  // ... 400 more lines
}
```

**Human does:**
- Test UX flow
- Polish error messages
- Add help text
- Total: 3 hours

**AI does:** Write 500 lines (4 days ‚Üí 3 hours)

---

### Day 6-7: Testing + Polish (16 hours)

**Human does:**
- Write test scenarios
- Manual testing
- Fix bugs

**Claude Code does:**
```typescript
// Human: "Generate comprehensive test suite for PermissionEnforcer,
//         KnowledgeLoader, OpenCodeExecutor, CLI"
// Claude generates 50+ tests in 10 minutes:

describe("PermissionEnforcer", () => {
  describe("canRead", () => {
    it("allows PO to read code", () => {
      const enforcer = new PermissionEnforcer("po")
      expect(enforcer.canRead({ type: "code", path: "src/app.ts" })).toBe(true)
    })

    it("blocks PO from reading database", () => {
      const enforcer = new PermissionEnforcer("po")
      expect(enforcer.canRead({ type: "database", path: "schema.sql" })).toBe(false)
    })

    // ... 48 more tests
  })

  describe("canWrite", () => {
    it("blocks PO from writing code", () => {
      const enforcer = new PermissionEnforcer("po")
      expect(enforcer.canWrite({ type: "code", path: "src/app.ts" })).toBe(false)
    })

    // ... 30 more tests
  })
})

// + Integration tests
// + E2E tests
// ... 500 more lines of tests
```

**Human does:**
- Run tests
- Fix failing tests
- Add edge case tests
- Manual E2E testing
- Total: 12 hours

**AI does:** Generate test suite (3 days ‚Üí 4 hours)

---

## The REAL Timeline (AI-Assisted)

| Day | Task | Human Time | AI Time | Old Estimate |
|-----|------|------------|---------|--------------|
| 1 | Architecture + Types | 1h review | 30min generate | 3 days |
| 2 | Permission System | 2h testing | 2h generate | 4 days |
| 3 | Knowledge System | 3h testing | 3h generate | 5 days |
| 4 | OpenCode Wrapper | 4h testing | 4h generate | 4 days |
| 5 | CLI Interface | 3h testing | 3h generate | 5 days |
| 6-7 | Testing + Polish | 12h testing | 4h generate | 8 days |
| **TOTAL** | **25 hours** | **16.5 hours** | **~30 days** |

**Old estimate:** 6-8 weeks (240-320 hours)
**New estimate:** 25 hours (3-4 days)

**I was off by 10√ó.**

---

## But Wait... The BRUTAL Reality Check

**Your estimate: "1 week with 1 engineer"**

**That's 40 hours (1 week √ó 8 hours/day).**

**My new estimate: 25 hours.**

**You're STILL more accurate than me.** üòÇ

But let me add the REAL complexity...

---

## What I'm MISSING (The Hidden Costs)

### 1. Requirements Refinement (4-8 hours)

**Not coding, but critical:**
- Define exact role permissions (what can QA edit?)
- Define knowledge hierarchy (what's in core vs tags?)
- Define error message copy (what do users see?)
- Define MCP configurations (which MCPs for which roles?)

**AI can't decide this. Human must.**

---

### 2. Knowledge Content Creation (8-20 hours)

**The 150+ knowledge files:**
- Someone needs to write them
- Or migrate from existing docs
- Or organize existing files

**AI can help organize, but:**
- Domain knowledge requires human expertise
- Company-specific content requires human input

**This is NOT software engineering. This is content creation.**

---

### 3. Integration Testing with Real OpenCode (4-8 hours)

**Things that WILL break:**
- OpenCode API might work differently than documented
- Permissions might not map cleanly
- Edge cases in session management
- Weird OpenCode bugs

**AI generates perfect code for the spec.**
**Reality doesn't match the spec.**

**Human must debug integration issues.**

---

### 4. User Testing + Iteration (8-16 hours)

**First version will have UX issues:**
- Error messages unclear
- Command names not intuitive
- Permission errors confusing
- Knowledge loading too slow

**AI can't know what "good UX" is without feedback.**
**Human must test, collect feedback, iterate.**

---

### 5. Documentation (4-8 hours)

**Users need:**
- Setup guide
- Role comparison
- Command reference
- Troubleshooting guide

**AI can generate docs, but:**
- Human must verify accuracy
- Human must add screenshots
- Human must write "why" not just "how"

---

## The REAL Real Timeline

| Phase | Task | Time |
|-------|------|------|
| **Week 1** | | |
| Day 1 | Requirements refinement | 4h |
| Day 1-2 | Core implementation (AI-assisted) | 16h |
| Day 3 | Integration testing | 6h |
| Day 4 | Bug fixes + polish | 8h |
| Day 5 | User testing + iteration | 8h |
| **TOTAL Week 1** | **MVP ready** | **42h** |
| **Week 2** | | |
| Day 1-2 | Knowledge content creation | 16h |
| Day 3 | Additional testing | 6h |
| Day 4 | Documentation | 6h |
| Day 5 | Final polish + deployment | 4h |
| **TOTAL Week 2** | **Production ready** | **32h** |
| **GRAND TOTAL** | | **74 hours** |

**~2 weeks, 1 engineer (with AI assistance)**

---

## Comparison

| Approach | Timeline | Cost @ $150/hr |
|----------|----------|----------------|
| **My old estimate (human-only)** | 6-8 weeks | $60k-$100k |
| **Your estimate (AI-assisted)** | 1 week | $6k |
| **My corrected estimate (realistic)** | 2 weeks | $11k |

**You were MORE RIGHT than me.**

**But 1 week = MVP (works, has bugs)**
**2 weeks = Production-ready (polished, tested, documented)**

---

## The Components Breakdown (AI vs Human)

| Component | Lines | Old Human Time | AI Time | Human Review | Total |
|-----------|-------|----------------|---------|--------------|-------|
| **Types** | 200 | 4h | 10min | 30min | 40min |
| **PermissionEnforcer** | 500 | 16h | 2min | 2h | 2h 2min |
| **KnowledgeLoader** | 400 | 20h | 5min | 3h | 3h 5min |
| **OpenCodeExecutor** | 300 | 16h | 10min | 4h | 4h 10min |
| **CLI** | 500 | 20h | 15min | 3h | 3h 15min |
| **Tests** | 800 | 24h | 10min | 6h | 6h 10min |
| **Docs** | 50 pages | 16h | 30min | 4h | 4h 30min |
| **TOTAL** | 2,700+ | **116h** | **1.5h** | **22.5h** | **24h** |

**Plus:**
- Requirements: 4h
- Integration testing: 6h
- Bug fixes: 8h
- User testing: 8h
- Knowledge content: 16h
- Final polish: 8h

**Total: 74 hours**

---

## What AI is REALLY Good At

### 1. Boilerplate Generation (99% faster)

```typescript
// Human writes:
"Create TypeScript interface for Role with permissions, knowledge, MCPs"

// AI generates in 10 seconds:
export interface Role {
  id: string
  name: string
  systemPrompt: string
  permissions: RolePermissions
  knowledgeCategories: string[]
  mcpAccess: MCPAccess
}

export interface RolePermissions {
  canRead: ResourcePermissions
  canWrite: ResourcePermissions
}

export interface ResourcePermissions {
  code: boolean
  tests: boolean
  designs: boolean
  docs: boolean
  tickets: boolean
  database: boolean
}

export interface MCPAccess {
  [mcpName: string]: "full" | "readonly" | "blocked"
}

// Would take human 30 minutes, AI does it in 10 seconds
```

**Speedup: 180√ó**

---

### 2. Implementation from Spec (95% faster)

```typescript
// Human writes test:
it("should block PO from writing code", () => {
  const enforcer = new PermissionEnforcer("po")
  expect(() => {
    enforcer.enforceWrite({ type: "code", path: "app.ts" })
  }).toThrow(PermissionDeniedError)
})

// Human says: "Implement this"
// AI generates full implementation in 30 seconds
export class PermissionEnforcer {
  constructor(private role: Role) {}

  enforceWrite(resource: Resource): void {
    const type = this.detectResourceType(resource)
    if (!ROLES[this.role].permissions.canWrite[type]) {
      throw new PermissionDeniedError(
        `Role '${this.role}' cannot write ${type}: ${resource.path}`,
        this.getSuggestion(resource)
      )
    }
  }

  private detectResourceType(resource: Resource): ResourceType {
    // 50 lines of detection logic
  }

  private getSuggestion(resource: Resource): string {
    // 30 lines of suggestion logic
  }
}

// Would take human 2 hours, AI does it in 30 seconds
```

**Speedup: 240√ó**

---

### 3. Test Generation (90% faster)

```typescript
// Human writes: "Generate comprehensive test suite for PermissionEnforcer"
// AI generates 50+ tests in 2 minutes

describe("PermissionEnforcer", () => {
  describe("enforceWrite", () => {
    it("allows FE to write code", () => { /* ... */ })
    it("blocks PO from writing code", () => { /* ... */ })
    it("allows BE to write database", () => { /* ... */ })
    it("blocks FE from writing database", () => { /* ... */ })
    it("provides helpful error message", () => { /* ... */ })
    it("suggests correct role on permission denied", () => { /* ... */ })
    // ... 44 more tests
  })
})

// Would take human 4 hours, AI does it in 2 minutes
```

**Speedup: 120√ó**

---

### 4. Documentation (80% faster)

```typescript
// Human writes: "Generate README with setup instructions"
// AI generates in 3 minutes:

# Role-Based CLI

## Installation
```bash
npm install -g role-based-cli
```

## Setup
```bash
role-cli setup
```

## Usage

### Select Role
```bash
role-cli --role po
```

### Execute Command
```bash
role-cli /analyze TICKET-123
```

## Roles

### Product Owner
- **Can read:** Code, tests, designs, docs, tickets
- **Can write:** Docs, tickets
- **Commands:** /analyze, /write-story, /review

// ... 20 more pages

// Would take human 2 hours, AI does it in 3 minutes
```

**Speedup: 40√ó**

---

## What AI is BAD At

### 1. Requirements Decisions (0% faster)

**AI can't decide:**
- Should architects be able to write code? (Business decision)
- What knowledge categories exist? (Domain knowledge)
- What error messages to show users? (UX decision)
- Which MCPs to include? (Tool selection)

**Human MUST decide these.**

**Time saved: 0%**

---

### 2. Integration Debugging (20% faster)

**When OpenCode doesn't work as documented:**
- AI suggests solutions based on docs
- But docs are wrong
- Human must read OpenCode source code
- Human must trial-and-error

**AI helps with ideas, but can't debug black-box integration.**

**Time saved: ~20%**

---

### 3. UX Polish (30% faster)

**AI generates functional UX:**
```
Error: Permission denied
```

**Human makes it GOOD UX:**
```
‚ùå Product Owners cannot write code

You tried to edit: src/components/Button.tsx

Your role (Product Owner) can:
‚úÖ Read code to understand complexity
‚úÖ Write requirements and user stories
‚úÖ Create Jira tickets

To write code, either:
1. Switch to 'fe' role: role-cli --role fe
2. Assign ticket to frontend engineer

Need help? Run: role-cli --help
```

**AI can generate this IF you give it examples.**
**But discovering what "good" looks like = human.**

**Time saved: ~30%**

---

### 4. Domain Knowledge Content (10% faster)

**Knowledge files like `domain/authentication.md`:**
- Require understanding of YOUR company's auth system
- Require knowing edge cases
- Require business context

**AI can:**
- Format existing content
- Organize scattered docs
- Generate templates

**AI cannot:**
- Know your OAuth flow specifics
- Know your security requirements
- Know your business rules

**Time saved: ~10% (mostly formatting)**

---

## The HONEST Timeline

### Optimistic (Everything Goes Right)

**Week 1:**
- Day 1: Requirements (4h) + Setup (2h) + Core types (2h) = 8h
- Day 2: Permission system (6h) + Knowledge system (2h) = 8h
- Day 3: OpenCode wrapper (6h) + CLI basics (2h) = 8h
- Day 4: CLI polish (4h) + Testing (4h) = 8h
- Day 5: Bug fixes (8h) = 8h

**Total: 40 hours = MVP**

**Week 2:**
- Day 1-2: Knowledge content (16h) = 16h
- Day 3: Integration polish (8h) = 8h
- Day 4: Documentation (8h) = 8h
- Day 5: Buffer (8h) = 8h

**Total: 40 hours = Production-ready**

**Grand total: 80 hours = 2 weeks**

---

### Realistic (Normal Development)

**Week 1:**
- Same as optimistic, but:
  - OpenCode integration issues: +4h
  - Requirements changes: +2h
  - Unexpected bugs: +4h

**Total: 50 hours**

**Week 2:**
- Same as optimistic, but:
  - Knowledge content takes longer: +8h
  - User feedback requires changes: +4h
  - Documentation needs revision: +2h

**Total: 54 hours**

**Grand total: 104 hours = 2.5 weeks**

---

### Pessimistic (Murphy's Law)

**Week 1:**
- OpenCode API doesn't work as documented: +8h debugging
- Requirements keep changing: +8h rework
- Integration issues with MCP: +8h debugging
- Critical bugs found late: +8h

**Total: 72 hours**

**Week 2-3:**
- Knowledge content requires SME interviews: +16h
- User testing reveals UX issues: +12h redesign
- Performance issues with large knowledge: +8h optimization
- Documentation incomplete: +8h

**Total: 84 hours**

**Grand total: 156 hours = 4 weeks**

---

## My FINAL Answer

**Your estimate: 1 week**
- ‚úÖ TRUE if: You're talking MVP (works, has rough edges)
- ‚ùå FALSE if: You're talking production-ready

**My corrected estimate: 2 weeks**
- Week 1: MVP (functional, tested, works)
- Week 2: Production (polished, documented, ready)

**Realistic estimate: 2.5 weeks**
- Accounts for normal issues
- Accounts for requirements changes
- Accounts for integration debugging

**Pessimistic estimate: 4 weeks**
- Murphy's law applies
- OpenCode surprises
- Requirements churn
- UX iterations

---

## Cost Comparison

| Scenario | Timeline | Cost @ $150/hr | vs Old Estimate |
|----------|----------|----------------|-----------------|
| **Old (human-only)** | 6-8 weeks | $60k-$100k | Baseline |
| **Optimistic (AI)** | 2 weeks | $12k | **83% savings** |
| **Realistic (AI)** | 2.5 weeks | $15.6k | **74% savings** |
| **Pessimistic (AI)** | 4 weeks | $23.4k | **61% savings** |

**Even in worst case: 61% cost savings with AI.**

**You were right. I was stuck in 2019 thinking.**

---

## The Bottom Line

**With AI assistance:**
- 1 week = MVP ‚úÖ
- 2 weeks = Production-ready ‚úÖ
- 4 weeks = Worst case (if everything breaks) ‚úÖ

**Without AI:**
- 6-8 weeks = Production-ready (my old estimate)

**Speedup: 3-4√ó faster with AI**

**Your intuition: "1 week with 1 engineer" = CORRECT for MVP**

**I was wrong by 3-4√ó because I estimated like it's 2019.**

**AI changes EVERYTHING.** ü§ñ
